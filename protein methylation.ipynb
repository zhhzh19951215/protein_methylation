{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19988, 30)\n",
      "(4996, 30)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                    False\n",
       "IP_ES_25_N1           False\n",
       "Z3_IB_4_N1            False\n",
       "Z1_IB_10_N1           False\n",
       "Z1_IB_5_N1            False\n",
       "Z3_IB_8_N1            False\n",
       "ECI_IB_4_N1           False\n",
       "ECI_IB_5_N1           False\n",
       "Gs(U)_IB_12_N1        False\n",
       "Gs(U)_IB_68_N1        False\n",
       "Gs(U)_IB_58_N1        False\n",
       "Gs(U)_IB_60_N1        False\n",
       "Z1_NO_sideL35_M       False\n",
       "HP_NO_sideL35_CV      False\n",
       "Z1_NO_sideR35_CV      False\n",
       "Pb_NO_sideR35_S       False\n",
       "IP_NO_sideL35_SI71    False\n",
       "Z1_NO_PRT_CV          False\n",
       "Z2_NO_AHR_CV          False\n",
       "Gs(U)_NO_ALR_SI71     False\n",
       "Z3_NO_UCR_S           False\n",
       "Z3_NO_UCR_N1          False\n",
       "ECI_NO_UCR_CV         False\n",
       "Pa_NO_BSR_SI71        False\n",
       "ISA_NO_NPR_S          False\n",
       "Z3_NO_NPR_V           False\n",
       "IP_NO_PLR_S           False\n",
       "Pb_NO_PCR_V           False\n",
       "ECI_NO_PCR_CV         False\n",
       "class                 False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('csv_result-Descriptors_Training.csv')\n",
    "df2 = pd.read_csv('csv_result-Descriptors_Calibration.csv')\n",
    "print(df1.shape)\n",
    "print(df2.shape)\n",
    "df1.isnull().any() #null value detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                    False\n",
       "IP_ES_25_N1           False\n",
       "Z3_IB_4_N1            False\n",
       "Z1_IB_10_N1           False\n",
       "Z1_IB_5_N1            False\n",
       "Z3_IB_8_N1            False\n",
       "ECI_IB_4_N1           False\n",
       "ECI_IB_5_N1           False\n",
       "Gs(U)_IB_12_N1        False\n",
       "Gs(U)_IB_68_N1        False\n",
       "Gs(U)_IB_58_N1        False\n",
       "Gs(U)_IB_60_N1        False\n",
       "Z1_NO_sideL35_M       False\n",
       "HP_NO_sideL35_CV      False\n",
       "Z1_NO_sideR35_CV      False\n",
       "Pb_NO_sideR35_S       False\n",
       "IP_NO_sideL35_SI71    False\n",
       "Z1_NO_PRT_CV          False\n",
       "Z2_NO_AHR_CV          False\n",
       "Gs(U)_NO_ALR_SI71     False\n",
       "Z3_NO_UCR_S           False\n",
       "Z3_NO_UCR_N1          False\n",
       "ECI_NO_UCR_CV         False\n",
       "Pa_NO_BSR_SI71        False\n",
       "ISA_NO_NPR_S          False\n",
       "Z3_NO_NPR_V           False\n",
       "IP_NO_PLR_S           False\n",
       "Pb_NO_PCR_V           False\n",
       "ECI_NO_PCR_CV         False\n",
       "class                 False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17107, 30)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_cleaning(df): #Implemention of zcore method\n",
    "    column_name = list(df1)[1:-1]\n",
    "    d = []\n",
    "    df_sum = df1.copy() #make a copy of df1\n",
    "    df_zscore = df1.copy() #make a copy of df1 to store the zscore\n",
    "    for i in column_name:\n",
    "        df_zscore[i] = (df1[i] - df1[i].mean())/df1[i].std()\n",
    "        b = df_zscore[df_zscore[i].abs()>3]['id']\n",
    "        d.append(list(b-1))\n",
    "    d = sum(d, [])\n",
    "    df_sum = df_sum.drop(df_sum.index[d])\n",
    "    return df_sum\n",
    "df_clean = data_cleaning(df1)\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2881"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape[0] - df_clean.shape[0] #number of bad data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "905"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.loc[df_clean['class']=='P'].shape[0] #number of postive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16202"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.loc[df_clean['class']=='N'].shape[0] #number of negative data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can see that there is a serious data imbalance in the data set. So we take the upsampling method for the positive data.\n",
    "def upsample():\n",
    "    df_sort = df_clean.sort_values(by = 'class', ascending = False) #Put positive data in the first 1042 rows\n",
    "    X_minor = df_sort.iloc[:905,:]\n",
    "    X_major = df_sort.iloc[905:,:]\n",
    "    df_minority_upsampled = resample(X_minor, \n",
    "                                     replace=True, # sample with replacement\n",
    "                                     n_samples=16202, # to match majority class\n",
    "                                     random_state=123) # reproducible results\n",
    "    df_upsampled = pd.concat([df_minority_upsampled, X_major])\n",
    "    return df_upsampled\n",
    "df_upsampled = upsample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16202"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_upsampled.loc[df_upsampled['class']=='P'].shape[0] #the number of positive data after upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32404, 28)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df_upsampled.iloc[:,1:29]\n",
    "X_test = df2.iloc[:,1:29]\n",
    "y_train = df_upsampled.iloc[:,29]\n",
    "y_test = df2.iloc[:,29]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 6\n",
      "8 23\n",
      "9 10\n",
      "9 23\n",
      "10 23\n",
      "19 20\n",
      "19 21\n",
      "20 21\n"
     ]
    }
   ],
   "source": [
    "#We are going to use a Bayesian classifier, so we need to remove features with high relevance\n",
    "#If the pearson coefficient is greater than 0.3, we consider it to be highly relevant.\n",
    "def redundancy(): #Calculate relavance.Choose features with pearson coefficient greater than 0.3.\n",
    "    corr =  np.asarray(X_train.corr())\n",
    "    Redundancy_coef = np.zeros(28)\n",
    "    for i in range(28):\n",
    "        Redundancy_coef[i] = np.mean(np.absolute(corr[:,i]))\n",
    "        for j in range(i+1,28):\n",
    "            if corr[j,i] >= 0.3:\n",
    "                print(i,j)\n",
    "redundancy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32404, 23) (4996, 23)\n"
     ]
    }
   ],
   "source": [
    "#Remove features with high relevance\n",
    "del_col = [5,9,19,21,23]\n",
    "X_train = X_train.drop(X_train.columns[del_col],axis=1)\n",
    "X_test = X_test.drop(X_test.columns[del_col],axis=1)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20, 12, 21,  7, 17, 11, 14, 15,  9,  2, 18,  8, 10,  5,  0,  4,  3,\n",
       "        6,  1, 19, 22, 13, 16], dtype=int64)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate the correlation between each feature and label. \n",
    "#Then calculate the value of (relavance-redundancy). \n",
    "#Finally we sorted the 23 features.\n",
    "X_train1 = np.asarray(X_train)\n",
    "X_test1 = np.asarray(X_test)\n",
    "y_train1 = np.asarray(y_train)\n",
    "y_test1 = np.asarray(y_test)\n",
    "for i in range(len(y_train1)):\n",
    "    if y_train1[i] == ('P'):\n",
    "        y_train1[i] = 1\n",
    "    else:\n",
    "        y_train1[i] = 0\n",
    "for i in range(len(y_test1)):\n",
    "    if y_test1[i] == ('P'):\n",
    "        y_test1[i] = 1\n",
    "    else:\n",
    "        y_test1[i] = 0\n",
    "def sort_list():\n",
    "    Relavance_coef = np.zeros(23)\n",
    "    Redundancy_coef = np.zeros(23)\n",
    "    for i in range(23):\n",
    "        Relavance_coef[i], p = stats.pearsonr(X_train1[:,i], y_train1)    \n",
    "    Relavance_abs = np.absolute(Relavance_coef)\n",
    "    corr =  np.asarray(X_train.corr())\n",
    "    for i in range(23):\n",
    "        Redundancy_coef[i] = np.mean(np.absolute(corr[:,i]))\n",
    "    Redundancy_abs = np.absolute(Redundancy_coef)\n",
    "    RR = Relavance_abs-Redundancy_abs\n",
    "\n",
    "    ind = np.argsort(-RR)\n",
    "    RR_sort = RR[np.argsort(-RR)]\n",
    "    return ind\n",
    "sort_list = sort_list()\n",
    "sort_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train1 = np.asarray(y_train1,dtype='int')\n",
    "y_test1 = np.asarray(y_test1,dtype='int')\n",
    "y_test1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5578462770216173\n"
     ]
    }
   ],
   "source": [
    "# Train a Bayesian classifier\n",
    "new_feature_train = X_train1[:,sort_list]\n",
    "new_feature_test = X_test1[:,sort_list]\n",
    "clf = GaussianNB()\n",
    "marks = []\n",
    "for i in range(23):\n",
    "    X_train_new1 = new_feature_train[:,:i+1] # input how many features\n",
    "    X_test_new1 = new_feature_test[:,:i+1]\n",
    "    clf.fit(X_train_new1,y_train1)\n",
    "    scores = clf.score(X_test_new1, y_test1)\n",
    "    marks.append(scores)\n",
    "print(max(marks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When there are 21 features, the accuracy can reach to 0.9423538831064852\n"
     ]
    }
   ],
   "source": [
    "# We found that accuracy was very low, so we tried to integrate the classifier using ensemble learning methods.\n",
    "mark_dict = {}\n",
    "for i in range(23):\n",
    "    X_train_new1 = new_feature_train[:,:i+1] # input how many features\n",
    "    X_test_new1 = new_feature_test[:,:i+1]\n",
    "    bdt = AdaBoostClassifier(clf,n_estimators=50)\n",
    "    bdt.fit(X_train_new1,y_train1)\n",
    "    scores1 = bdt.score(X_test_new1, y_test1)\n",
    "    mark_dict[i+1] = scores1\n",
    "a = sorted(mark_dict.items(), key=lambda x: x[1],reverse = True)\n",
    "print(\"When there are {0} features, the accuracy can reach to {1}\".format(a[0][0],a[0][1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
